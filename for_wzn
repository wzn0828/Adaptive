1\ In the step of 'Normalize', why the mean value and standard deviation are these values? A: That's decided by ImageNet.
2\ check vocab is or not right.
3\ beam search.
4\ train vision.
5\ loss curve:YES
6\ Decoder has no initialization for h0 & c0.
7\ Check whether bidirectional LSTM identify bideirectional RNN: no;
8\ initialization for the lstm of rnn_attention is zero.
9\ check the last hidden output of bidirectional lstm is or not the concatination of two hidden_T: Checked, the result is not, but has modified.
10\ the calculation for output yt may be too simple.
11\ lstm clip choice.
12\ lstm add batchnorm or not.
13\ make every count clear: count of train/valid/test images, annos; max length of annos;
14\ to make relationship between batch and count clear;
15\ Do not save resnet parameters when save state_dict
16\ compare dataloader between train's and validation's
17\ Do not save the part of dicti of Resnet, which is not optimized during training.
18\ loss figure, the axis should be [1,2,...]
19\ logfile has no content at the begining.
20\ left freedom: learning rate; resnet all layer optimization; train_clip or not or lstm_gradient_clip;optimization methods;batch norm; add loss;structure;
21\ when shuffling, what's the difference between rand and randn ?
